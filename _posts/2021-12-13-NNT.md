---
layout: single
title:  "Chapter4. Neural Network Training"
categories: ['Deep Learning from Scratch']
tag: ['deep learning', 'neural network', 'gradient descent']
---

Neural network training is a process that will automatically produce the optimized weight values.
A loss function is function that shows error rate of prediction. An optimization problem seeks to minimize a loss function.
We would need to find weight and bias to minimize a loss function.


### Sum of Squares for Error(SSE)
E = 1/2 ∑(yk-tk)^2 where   
yk stands for the output value  
tk stands for the label  
k stands for the dimension  
 
```python
import numpy as np
```


```python
# Define Sum of Squres for Error(SSE)
def sum_squares_error (y,t):
    return 0.5 * np.sum((y-t)**2)
```


```python
# When the output predicted the probability
# of the correct answer '2' is the higest(0.6)
# -> predicted correctly
y = [.1, .05, .6, 0, .05, .1, 0, .1, 0, 0] # output values
t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0] # label(the answer is actually '2')
```


```python
sum_squares_error(np.array(y), np.array(t))
```




    0.09750000000000003




```python
# When the output predicted the probability
# of the correct answer '7' is the higest(0.6)
# -> predicted incorrectly
y = [.1, .05, 0.1, 0, .05, .1, 0, .6, 0, 0] # output values
t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0] # label(the answer is actually '2')
```


```python
sum_squares_error(np.array(y), np.array(t))
```




    0.5975

### Cross Entropy Error(CEE)
E = -∑tk * logyk where  
yk is the output  
tk is the label(only the index for the correct answer is 1 and 0 for else - One Hot Encoding).  

```python
# Define Cross Entropy Error(CEE)
def cross_entropy_error(y,t):
    delta = 1e-7 #preventing an overflow
    return -np.sum(t * np.log(y+delta))
```


```python
# When the output predicted the probability
# of the correct answer '2' is the higest(0.6)
# -> predicted correctly
y = [.1, .05, .6, 0, .05, .1, 0, .1, 0, 0] # output values
t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0] # label(the answer is actually '2')
```


```python
cross_entropy_error(np.array(y),np.array(t))
```




    0.510825457099338




```python
# When the output predicted the probability
# of the correct answer '7' is the higest(0.6)
# -> predicted incorrectly
y = [.1, .05, 0.1, 0, .05, .1, 0, .6, 0, 0] # output values
t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0] # label(the answer is actually '2')
```


```python
cross_entropy_error(np.array(y),np.array(t))
```




    2.302584092994546


### Mini Batch
When we have multiple training dataset, we need to use sum of loss functions of each training set.
In equation,  
E = -1/N ∑ ∑tnk logyk  

However, as the size of dataset gets bigger, computing gets costly. It's not realistict to compute loss function in big data.
This is why we use mini batch which randomly select a small number of data and train them.

```python
import sys, os
sys.path.append(os.pardir)
import numpy as np
from dataset.mnist import load_mnist

(x_train, t_train), (x_test, t_test ) = \
    load_mnist(normalize = True, one_hot_label = True)

print(x_train.shape)
print(t_train.shape)
```

    (60000, 784)
    (60000, 10)
    


```python
train_size = x_train.shape[0]
batch_size = 10
batch_mask = np.random.choice(train_size, batch_size)
x_batch = x_train[batch_mask]
t_batch = t_train[batch_mask]
```


```python
# When label is one hot encoded 
def cross_entropy_error(y,t):
    if y.ndim == 1:
        t = t.reshape(1, t.size) # label
        y = y.reshape(1, y.size) # output
    batch_size = y.shape[0]
    return -np.sum(t * np.log(y+1e-7)) / batch_size
```


```python
# When label is NOT one hot encoded 
def cross_entropy_error(y,t):
    if y.ndim == 1:
        t = t.reshape(1, t.size) # label
        y = y.reshape(1, y.size) # output
    batch_size = y.shape[0]
    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7))/batch_size
```

### Why Using Loss Function?
To answer this question, we need to look into how "differentiation"(inclination) works in neural network.  
In neural network training, to optimize the values of parameters(weight and bias), it minimizes loss function by calculation inclination of parameters.
For example, in a neural network when a differentiated parameter has a negative value, it can be optimized by moving it forward to a positive value.

Accuracy can't be an indicator how good the model is in neural network because accuracy, precision, and recall aren't differentiable, so we can't use them to optimize our machine learning models.

## Numerical Differentiation
Gradient descent is a first-order iterative optimization algorithm for finding a local minimum of a differentiable function.

### Differentiation
Differentiation is a process of finding a function that outputs the rate of change of one variable with respect to another variable.
In equation,  
![image2021_12_18](https://user-images.githubusercontent.com/69702946/146631306-e8df912d-44a1-47e3-b9b3-047d9a65bb5a.png)  
```python
def numerical_diff(f,x):
    h = 1e-4 # 0.0001
    return(f(x+h)) - f(x-h)/(2*h)
```
NOTE: This is called numerical differentiation. Numerical methods use exact algorithms to present numerical solutions to mathematical problems. Analytical is exact; numerical is approximate. For example, some differential equations cannot be solved exactly (analytic or closed form solution) and we must rely on numerical techniques to solve them. 


### An Example of Numerical Differentiation
```python
# When y = 0.01x^2 + 0.1x
def function_1(x):
    return 0.01*x**2 + 0.1*x
```


```python
import numpy as np
import matplotlib.pyplot as plt
x = np.arange(0.0, 20.0, 0.1)
y = function_1(x)
plt.xlabel("x")
plt.ylabel("f(x)")
plt.plot(x,y)
plt.show()
```


![output_2_0](https://user-images.githubusercontent.com/69702946/146631698-51e71551-35e5-401d-9d67-ef5eced9673d.png)




```python
# When x = 5
numerical_diff(function_1,5)
```




    0.1999999999990898




```python
# when x = 10
numerical_diff(function_1, 10)
```




    0.2999999999986347
    
    
## Gradient descent
Gradient descent is a first-order iterative optimization algorithm for finding a local minimum of a differentiable function. The idea is to take repeated steps in the opposite direction of the gradient (or approximate gradient) of the function at the current point, because this is the direction of steepest descent. Conversely, stepping in the direction of the gradient will lead to a local maximum of that function; the procedure is then known as gradient ascent.  
In equation,  
![image20211218_2](https://user-images.githubusercontent.com/69702946/146633433-29d176a1-3dbc-4294-84aa-b25053b49ac9.png)  
  
  
eta stands for learning rate. With a high learning rate we can cover more ground each step, but we risk overshooting the lowest point since the slope of the hill is constantly changing. With a very low learning rate, we can confidently move in the direction of the negative gradient since we are recalculating it so frequently. A low learning rate is more precise, but calculating the gradient is time-consuming, so it will take us a very long time to get to the bottom.
```python
def numerical_gradient(f,x):
    h = 1e-4 # 0.0001
    grad = np.zeros_like(x) # shpae of x
    
    for idx in range(x.size):
        tmp_val = x[idx]
        
        # f(x+h)
        x[idx] = tmp_val + h
        fxh1 = f(x)
        
        # f(x-h)
        x[idx] = tmp_val - h
        fxh2 = f(x)

        grad[idx] = (fxh1 - fxh2)/(2*h)
        x[idx] = tmp_val
    return grad
        
           
```


```python
def gradient_descent(f, init_x, lr = 0.01, step_num = 100):
    x = init_x
    
    for i in range(step_num):
        grad = numerical_gradient(f,x)
        x -= lr * grad
    return x
# f for the function that we're tryna optimize
# init_x for the initation value
# lr for learning rate
# step_num for the number of repeats
```


```python
# Example:
# when f(x0, x1) = x^2 + x1^2,
# find the minimum value of f(x0, x1)
def function_2(x):
    return x[0]**2 + x[1]**2

init_x  = np.array([-3.0, 4.0])
gradient_descent(function_2, init_x = init_x, lr = 0.1, step_num = 100)
```




    array([-6.11110793e-10,  8.14814391e-10])

Note: Learning rate should neither be too big nor be too small; otherwise, the performance won't be that great.

```python
# An example of learning rate to be too big
init_x = np.array([-3.0, 4.0])
gradient_descent(function_2, init_x = init_x, 
                 lr = 10.0, step_num = 100)
# the output is too big
```




    array([-2.58983747e+13, -1.29524862e+12])




```python
# An example of learning rate to be too small
init_x = np.array([-3.0, 4.0])
gradient_descent(function_2, init_x = init_x, 
                 lr = 1e-10, step_num = 100)
# the output is too small
```




    array([-2.99999994,  3.99999992])
    
    
