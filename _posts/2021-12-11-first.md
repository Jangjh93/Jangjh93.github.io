---
layout: single
title:  "Perceptron"
categories: Deep Learning from Scratch
tag: python, deeplearning
---

## Chapter2.
In machine learning, the perceptron is an algorithm for supervised learning of binary classifiers. 
A binary classifier is a function which can decide whether or not an input, 
represented by a vector of numbers, belongs to some specific class

Equation for Perceptron:
y = 0 (w1x1 + w2x2 <= θ)
  = 1 (w1x2 + w2x2 >  θ)

As we see in the equation, we add weights on each imput(x1,x2)
which implies that as bigger the weight is, it gets more significant.

# Appying Perceptron on "AND Gate"

AND gate has two inputs and one output.
The output will be '1' only when it has '1' for both inputs. 
Using a truth table as an example,
x1  x2 |y
0   0  |0
1   0  |0
0   1  |0
1   1  |1
How do we express the AND gate by using perceptron?
-> We need to define (w1, w2, θ) that would work as the truth table above.
ex. (0.5, 0.5 0.7), (0.5, 0.5,0.8), ...

# "Applying Perceptron on NAND Gate, OR Gate"
NAND means "Not AND".
It's bascially reversed version of And gate.
Using a truth table as an example,
x1  x2 |y
0   0  |1
1   0  |1
0   1  |1
1   1  |0
We can simply apply NAND gate on perceptron with combinations like 
(w1, w2, θ) = (-.5, -.5 -.7)















