---
layout: single
title:  "Chapter4. Neural Network Training"
categories: ['Deep Learning from Scratch']
tag: ['deep learning', 'neural network', 'gradient descent']
---

Neural network training is a process that will automatically produce the optimized weight values.
A loss function is function that shows error rate of prediction. An optimization problem seeks to minimize a loss function.
We would need to find weight and bias to minimize a loss function.


### Sum of Squares for Error(SSE)
E = 1/2 ∑(yk-tk)^2 where   
yk stands for the output value  
tk stands for the label  
k stands for the dimension  
 
```python
import numpy as np
```


```python
# Define Sum of Squres for Error(SSE)
def sum_squares_error (y,t):
    return 0.5 * np.sum((y-t)**2)
```


```python
# When the output predicted the probability
# of the correct answer '2' is the higest(0.6)
# -> predicted correctly
y = [.1, .05, .6, 0, .05, .1, 0, .1, 0, 0] # output values
t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0] # label(the answer is actually '2')
```


```python
sum_squares_error(np.array(y), np.array(t))
```




    0.09750000000000003




```python
# When the output predicted the probability
# of the correct answer '7' is the higest(0.6)
# -> predicted incorrectly
y = [.1, .05, 0.1, 0, .05, .1, 0, .6, 0, 0] # output values
t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0] # label(the answer is actually '2')
```


```python
sum_squares_error(np.array(y), np.array(t))
```




    0.5975

### Cross Entropy Error(CEE)
E = -∑tk * logyk where  
yk is the output  
tk is the label(only the index for the correct answer is 1 and 0 for else - One Hot Encoding).  

```python
# Define Cross Entropy Error(CEE)
def cross_entropy_error(y,t):
    delta = 1e-7 #preventing an overflow
    return -np.sum(t * np.log(y+delta))
```


```python
# When the output predicted the probability
# of the correct answer '2' is the higest(0.6)
# -> predicted correctly
y = [.1, .05, .6, 0, .05, .1, 0, .1, 0, 0] # output values
t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0] # label(the answer is actually '2')
```


```python
cross_entropy_error(np.array(y),np.array(t))
```




    0.510825457099338




```python
# When the output predicted the probability
# of the correct answer '7' is the higest(0.6)
# -> predicted incorrectly
y = [.1, .05, 0.1, 0, .05, .1, 0, .6, 0, 0] # output values
t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0] # label(the answer is actually '2')
```


```python
cross_entropy_error(np.array(y),np.array(t))
```




    2.302584092994546


### Mini Batch
When we have multiple training dataset, we need to use sum of loss functions of each training set.
In equation,  
E = -1/N ∑ ∑tnk logyk  

However, as the size of dataset gets bigger, computing gets costly. It's not realistict to compute loss function in big data.
This is why we use mini batch which randomly select a small number of data and train them.

```python
import sys, os
sys.path.append(os.pardir)
import numpy as np
from dataset.mnist import load_mnist

(x_train, t_train), (x_test, t_test ) = \
    load_mnist(normalize = True, one_hot_label = True)

print(x_train.shape)
print(t_train.shape)
```

    (60000, 784)
    (60000, 10)
    


```python
train_size = x_train.shape[0]
batch_size = 10
batch_mask = np.random.choice(train_size, batch_size)
x_batch = x_train[batch_mask]
t_batch = t_train[batch_mask]
```


```python
# When label is one hot encoded 
def cross_entropy_error(y,t):
    if y.ndim == 1:
        t = t.reshape(1, t.size) # label
        y = y.reshape(1, y.size) # output
    batch_size = y.shape[0]
    return -np.sum(t * np.log(y+1e-7)) / batch_size
```


```python
# When label is NOT one hot encoded 
def cross_entropy_error(y,t):
    if y.ndim == 1:
        t = t.reshape(1, t.size) # label
        y = y.reshape(1, y.size) # output
    batch_size = y.shape[0]
    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7))/batch_size
```

### Why Using Loss Function?
To answer this question, we need to look into how "differentiation"(inclination) works in neural network.  
In neural network training, to optimize the values of parameters(weight and bias), it minimizes loss function by calculation inclination of parameters.
For example, in a neural network when a differentiated parameter has a negative value, it can be optimized by moving it forward to a positive value.

Accuracy can't be an indicator how good the model is in neural network because accuracy, precision, and recall aren't differentiable, so we can't use them to optimize our machine learning models.

## Numerical Differentiation
Gradient descent is a first-order iterative optimization algorithm for finding a local minimum of a differentiable function.

### Differentiation
Differentiation is a process of finding a function that outputs the rate of change of one variable with respect to another variable.
In equation,  
![image2021_12_18](https://user-images.githubusercontent.com/69702946/146631306-e8df912d-44a1-47e3-b9b3-047d9a65bb5a.png)  
```python
def numerical_diff(f,x):
    h = 1e-4 # 0.0001
    return(f(x+h)) - f(x-h)/(2*h)
```
NOTE: This is called numerical differentiation. Numerical methods use exact algorithms to present numerical solutions to mathematical problems. Analytical is exact; numerical is approximate. For example, some differential equations cannot be solved exactly (analytic or closed form solution) and we must rely on numerical techniques to solve them. 


### An Example of Numerical Differentiation
```python
# When y = 0.01x^2 + 0.1x
def function_1(x):
    return 0.01*x**2 + 0.1*x
```


```python
import numpy as np
import matplotlib.pyplot as plt
x = np.arange(0.0, 20.0, 0.1)
y = function_1(x)
plt.xlabel("x")
plt.ylabel("f(x)")
plt.plot(x,y)
plt.show()
```


![output_2_0](https://user-images.githubusercontent.com/69702946/146631698-51e71551-35e5-401d-9d67-ef5eced9673d.png)




```python
# When x = 5
numerical_diff(function_1,5)
```




    0.1999999999990898




```python
# when x = 10
numerical_diff(function_1, 10)
```




    0.2999999999986347
    
    
## Gradient descent
Gradient descent is a first-order iterative optimization algorithm for finding a local minimum of a differentiable function. The idea is to take repeated steps in the opposite direction of the gradient (or approximate gradient) of the function at the current point, because this is the direction of steepest descent. Conversely, stepping in the direction of the gradient will lead to a local maximum of that function; the procedure is then known as gradient ascent.  
In equation,  
![image20211218_2](https://user-images.githubusercontent.com/69702946/146633433-29d176a1-3dbc-4294-84aa-b25053b49ac9.png)  
  
  
eta stands for learning rate. With a high learning rate we can cover more ground each step, but we risk overshooting the lowest point since the slope of the hill is constantly changing. With a very low learning rate, we can confidently move in the direction of the negative gradient since we are recalculating it so frequently. A low learning rate is more precise, but calculating the gradient is time-consuming, so it will take us a very long time to get to the bottom.
```python
def numerical_gradient(f,x):
    h = 1e-4 # 0.0001
    grad = np.zeros_like(x) # shpae of x
    
    for idx in range(x.size):
        tmp_val = x[idx]
        
        # f(x+h)
        x[idx] = tmp_val + h
        fxh1 = f(x)
        
        # f(x-h)
        x[idx] = tmp_val - h
        fxh2 = f(x)

        grad[idx] = (fxh1 - fxh2)/(2*h)
        x[idx] = tmp_val
    return grad
        
           
```


```python
def gradient_descent(f, init_x, lr = 0.01, step_num = 100):
    x = init_x
    
    for i in range(step_num):
        grad = numerical_gradient(f,x)
        x -= lr * grad
    return x
# f for the function that we're tryna optimize
# init_x for the initation value
# lr for learning rate
# step_num for the number of repeats
```


```python
# Example:
# when f(x0, x1) = x^2 + x1^2,
# find the minimum value of f(x0, x1)
def function_2(x):
    return x[0]**2 + x[1]**2

init_x  = np.array([-3.0, 4.0])
gradient_descent(function_2, init_x = init_x, lr = 0.1, step_num = 100)
```




    array([-6.11110793e-10,  8.14814391e-10])

Note: Learning rate should neither be too big nor be too small; otherwise, the performance won't be that great.

```python
# An example of learning rate to be too big
init_x = np.array([-3.0, 4.0])
gradient_descent(function_2, init_x = init_x, 
                 lr = 10.0, step_num = 100)
# the output is too big
```




    array([-2.58983747e+13, -1.29524862e+12])




```python
# An example of learning rate to be too small
init_x = np.array([-3.0, 4.0])
gradient_descent(function_2, init_x = init_x, 
                 lr = 1e-10, step_num = 100)
# the output is too small
```




    array([-2.99999994,  3.99999992])
    
    
## Inclination in Neural Network
In neural network, we need to calculatie inclination of loss function for parameters.  
For example, a neural network that has a shape of 2 X 3, W(weight), L(loss function)  

![image20211218_3](https://user-images.githubusercontent.com/69702946/146634540-a4704bad-2005-4ad0-8871-5359dd3472e8.png)  




```python
def softmax(a):
    exp_a = np.exp(a)
    sum_exp_a = np.sum(exp_a)
    y = exp_a/sum_exp_a
    return y

def cross_entropy_error(y,t):
    delta = 1e-7 #preventing an overflow
    return -np.sum(t * np.log(y+delta))

def numerical_gradient(f, x):
    h = 1e-4 # 0.0001
    grad = np.zeros_like(x)
    
    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])
    while not it.finished:
        idx = it.multi_index
        tmp_val = x[idx]
        x[idx] = tmp_val + h
        fxh1 = f(x) # f(x+h)
        
        x[idx] = tmp_val - h 
        fxh2 = f(x) # f(x-h)
        grad[idx] = (fxh1 - fxh2) / (2*h)
        
        x[idx] = tmp_val #
        it.iternext()   
        
    return grad
```


```python
class simpleNet:
    def __init__(self):
        self.W = np.random.randn(2,3) # normalize
        
    def predict(self, x):
        return np.dot(x, self.W)
    
    def loss(self, x, y):
        z = self.predict(x)
        y = softmax(z)
        loss = cross_entropy_error(y, t)
        
        return loss
# x for input data
# t for the label
```


```python
net = simpleNet()
print(net.W)
```

    [[ 1.25615955 -0.23526327 -0.89640755]
     [ 0.08626607 -2.37387257  2.25933404]]
    


```python
x = np.array([0.6, 0.9])
p = net.predict(x)
print(p)
```

    [ 0.8313352  -2.27764328  1.4955561 ]
    


```python
np.argmax(p)
```




    2




```python
t = np.array([0, 0, 1]) # the label
net.loss(x, t)
```




    0.43025693034504336




```python
# define f(w) dummy to keep the same seed value
def f(W):
    return net.loss(x,t)

dW = numerical_gradient(f, net.W)
print(dW)

```

    [[ 0.20082854  0.0089663  -0.20979484]
     [ 0.30124281  0.01344945 -0.31469226]]
    


Interpretation: Dw is result of numerical gradient(f, net.W) which shas a shape of 2 X 3(two dimentional array)  
∂L/∂W11 is close to 0.2, this implies when you increase w11 as much as h, then the loss function will increase as 0.2h.  
∂L/∂W23 is close to -0.3, this implie when you increase w23 as much as h, then the loss function will decrease as 0.5h.  
Thus, ∂L/∂W11 is supposed to move towrard negative and ∂L/∂W23 is supposed to move toward positive.


## Implementing a Training Algorithm.
Neural network will have parameters(weight, bias) and we will adjust the parameter.  
This process is called training. Neural network training procedure will be:  
Step1: Mini Batch  
We randomly pick sample data and our goal is to minimize the loss of information from mini batch.  
  
Step2: Calcuating Inclination  
To minimize the loss function, we calculate inclination of each of parameter and this will suggest how to minimize the loss function.  
  
Step3: Updating the Parameters  
We update the parameters slightly in the inclination direction.  
  
Step4: Repeating  
Repeat Step1 ~ Step3  

This process is how nueral network is built. It's a way to update the parameters basing on gradient descent and it's called to be "SGD(Stochastic Gradient Descent)" because
we randomly select the sample with mini batch.
  
Implementing this process on MNIST dataset with two layer net,
```python
import numpy as np
import matplotlib.pyplot as plt
```


```python
def sigmoid(x):
    return 1 / (1 + np.exp(-x))    

def softmax(x):
    x = x - np.max(x, axis=-1, keepdims=True)   # preventing overflow
    return np.exp(x) / np.sum(np.exp(x), axis=-1, keepdims=True)

def numerical_gradient(f, x):
    h = 1e-4 # 0.0001
    grad = np.zeros_like(x)
    
    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])
    while not it.finished:
        idx = it.multi_index
        tmp_val = x[idx]
        x[idx] = tmp_val + h
        fxh1 = f(x) # f(x+h)
        
        x[idx] = tmp_val - h 
        fxh2 = f(x) # f(x-h)
        grad[idx] = (fxh1 - fxh2) / (2*h)
        
        x[idx] = tmp_val # restore the value
        it.iternext()   
        
    return grad

def cross_entropy_error(y,t):
    if y.ndim == 1:
        t = t.reshape(1, t.size)
        y = y.reshape(1, y.size)
        
    if t.size == y.size:
        t = t.argmax(axis=1)
             
    batch_size = y.shape[0]
    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size
```

# Define TwoLayerNet

### params: dictionary variables for parameters of the neural network
##### params['W1'] = weight in the first layer
##### params['b1'] = bias in the first layer
##### params['W2'] = weight in the second layer
##### params['b2'] = bias in the second layer

### grads: dictionary variables for the gradient(inclination)
##### grads['W1'] = gradient of weight in the first layer
##### grads['b1'] = gradient of bias in the first layer
##### grads['W2'] = gradient of weight in the second layer
##### grads['b2'] = gradient of bias in the second layer


```python
class TwoLayerNet:

    def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01):
        # restting the parameters 
        self.params = {}
        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)
        self.params['b1'] = np.zeros(hidden_size)
        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size)
        self.params['b2'] = np.zeros(output_size)

    def predict(self, x):
        W1, W2 = self.params['W1'], self.params['W2']
        b1, b2 = self.params['b1'], self.params['b2']
    
        a1 = np.dot(x, W1) + b1
        z1 = sigmoid(a1)
        a2 = np.dot(z1, W2) + b2
        y = softmax(a2)
        
        return y
        
    # x:input data, t: the label
    def loss(self, x, t):
        y = self.predict(x)
        
        return cross_entropy_error(y, t)
    
    def accuracy(self, x, t):
        y = self.predict(x)
        y = np.argmax(y, axis=1)
        t = np.argmax(t, axis=1)
        
        accuracy = np.sum(y == t) / float(x.shape[0])
        return accuracy
        
    # x:input data, t: the label
    def numerical_gradient(self, x, t):
        loss_W = lambda W: self.loss(x, t)
        
        grads = {}
        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])
        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])
        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])
        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])
        
        return grads
```


```python
# Mini batch
from dataset.mnist import load_mnist
(x_train, t_train), (x_test,t_test) =\
    load_mnist(normalize = True, one_hot_label = True)


network = TwoLayerNet(input_size = 784, hidden_size = 50,
                    output_size = 10)

# Hyperparameter
iters_num = 10000 # number of repeats
train_size = x_train.shape[0]
batch_size = 100 # size of mini batch
learning_rate = 0.1


train_loss_list = []
train_acc_list = []
test_acc_list = []

# number of repeats per 1 epoch
iter_per_epoch = max(train_size / batch_size, 1)

for i in range(iters_num):
    # getting mini batch
    batch_mask = np.random.choice(train_size, batch_size)
    x_batch = x_train[batch_mask]
    t_batch = t_train[batch_mask]
        
    # calcuating the gradient
    grad = network.numerical_gradient(x_batch, t_batch)
    
    # updating the parameters
    for key in ('W1', 'b1', 'W2', 'b2'):
        network.params[key] -= learning_rate * grad[key]
    
    # restore the value
    loss = network.loss(x_batch, t_batch)
    train_loss_list.append(loss)
  
    # calculating accuracy per one epoch
    if i % iter_per_epoch == 0:
        train_acc = network.accuracy(x_train, t_train)
        test_acc = network.accuracy(x_test, t_test)
        train_acc_list.append(train_acc)
        test_acc_list.append(test_acc)
        print("train acc, test acc | " + str(train_acc) + ", " + str(test_acc))
        
# Drawing the graph
markers = {'train': 'o', 'test': 's'}
x = np.arange(len(train_acc_list))
plt.plot(x, train_acc_list, label='train acc')
plt.plot(x, test_acc_list, label='test acc', linestyle='--')
plt.xlabel("epochs")
plt.ylabel("accuracy")
plt.ylim(0, 1.0)
plt.legend(loc='lower right')
plt.show()
```
![image20211218_4](https://user-images.githubusercontent.com/69702946/146642707-3b2443d9-5bc5-4f57-8e4d-5a2ac6e46934.png)

Note: An epoch is a term used in machine learning and indicates the number of passes of the entire training dataset the machine learning algorithm has completed. Datasets are usually grouped into batches (especially when the amount of data is very large).  
  
Result: As epochs increase, it gets higher accuracy and it doesn't show much of difference between the train acc and the test acc; this implies that 
overfitting didn't happen.

Reference: https://github.com/Jangjh93/deep-learning-from-scratch/tree/master/ch04














