---
layout: single
title:  "Chapter4. Neural Network Training"
categories: ['Deep Learning from Scratch']
tag: ['deep learning', 'neural network']
---

Neural network training is a process that will automatically produce the optimized weight values.
A loss function is function that shows error rate of prediction. An optimization problem seeks to minimize a loss function.
We would need to find weight and bias to minimize a loss function.


### Sum of Squares for Error(SSE)
E = 1/2 âˆ‘(yk-tk)^2 where   
yk stands for the output value  
tk stands for the label  
k stands for the dimension  
 
```python
import numpy as np
```


```python
# define Sum of Squres for Error(SSE)
def sum_squares_error (y,t):
    return 0.5 * np.sum((y-t)**2)
```


```python
# When the output predicted the probability
# of the correct answer '2' is the higest(0.6)
# -> predicted correctly
y = [.1, .05, .6, 0, .05, .1, 0, .1, 0, 0] # output values
t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0] # label(the answer is actually '2')
```


```python
sum_squares_error(np.array(y), np.array(t))
```




    0.09750000000000003




```python
# When the output predicted the probability
# of the correct answer '7' is the higest(0.6)
# -> predicted incorrectly
y = [.1, .05, 0.1, 0, .05, .1, 0, .6, 0, 0] # output values
t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0] # label(the answer is actually '2')
```


```python
sum_squares_error(np.array(y), np.array(t))
```




    0.5975




