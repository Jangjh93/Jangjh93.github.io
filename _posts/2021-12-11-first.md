---
layout: single
title:  "Perceptron"
categories: DeepLearningfromScratch
tag: ['deeplearning']
---

# Chapter2.
In machine learning, the perceptron is an algorithm for supervised learning of binary classifiers. 
A binary classifier is a function which can decide whether or not an input, 
represented by a vector of numbers, belongs to some specific class

Equation for Perceptron:  
y = 0 (w1x1 + w2x2 <= θ)  
y = 1 (w1x2 + w2x2 >  θ)  

As we see in the equation, we add weights on each imput(x1,x2)
which implies that as bigger the weight is, it gets more significant.

## Appying Perceptron on "AND Gate"
AND gate has two inputs and one output.
The output will be '1' only when it has '1' for both inputs.
Drawing a truth table for AND gate,
x1  x2  y  
0   0   0  
1   0   0  
0   1   0  
1   1   1  

How do we express the AND gate by using perceptron?
-> We need to define (w1, w2, θ) that would work as the truth table above.
ex. (0.5, 0.5 0.7), (0.5, 0.5,0.8), ...

## Applying Perceptron on "NAND Gate" and "OR Gate"
NAND means "Not AND".
It's bascially reversed version of And gate.

We can simply apply NAND gate on perceptron with combinations like  
(w1, w2, θ) = (-.5, -.5 -.7)


OR Gate would print '1' when one of the input is bigger than 1.  
(w1, w2, θ) = (0.5, 0.5, -0.2)












